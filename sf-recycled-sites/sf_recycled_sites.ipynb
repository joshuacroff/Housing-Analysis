{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import getpass\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "sys.path.insert(0, f\"/Users/{user}/Documents/GitHub/Housing-Analysis\")\n",
    "\n",
    "from housing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A public ArcGIS Online account is required to pull data from ArcGIS Online using the arcgis python api.\n",
    "# Link to create an account: https://doc.arcgis.com/en/arcgis-online/get-started/create-account.htm\n",
    "password = os.environ.get(\"AGOL_PUBLIC_PASSWORD\")\n",
    "gis = GIS(username=\"joshua.croff@gmail.com\", password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read housing sites inventory\n",
    "sites_df = pd.read_excel(\"Data/AppendixB4.xlsx\", sheet_name=1, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking feature service layer IDs into 188 chunks\n"
     ]
    }
   ],
   "source": [
    "# read cycle 4 and 5 housing element sites inventory\n",
    "url =\"https://services3.arcgis.com/i2dkYWmb4wHvYPda/arcgis/rest/services/regional_housing_need_assessment_sites/FeatureServer/0\"\n",
    "prev_sites_df = pull_geotable_agol(base_url=url, client=gis, reproject_to_analysis_crs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe that only includes sites in San Francisco\n",
    "prev_sites_sf_df = prev_sites_df.query(\"jurisdict == 'San Francisco'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix apn formatting from MTC/ABAG data to match SF data\n",
    "prev_sites_sf_df[\"apn_fmt\"] = prev_sites_sf_df[\"apn\"].str.replace(\"/\",\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast all columns to lowercase\n",
    "sites_df.columns = sites_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "sites_df.rename(columns={\"mapblklot\": \"apn_fmt\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge sites dataframes\n",
    "sites_merge_df = pd.merge(sites_df, prev_sites_sf_df, on=\"apn_fmt\", how=\"outer\", indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "left_only     115067\n",
       "both            8396\n",
       "right_only      2366\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check merge results\n",
    "sites_merge_df[\"_merge\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flag binary flag columns to indicate if site used in previous housing element\n",
    "sites_merge_df[\"sf_used_in_previous_he\"] = np.where(\n",
    "    sites_merge_df[\"id_last2\"] == \"Used in Prior Housing Element - Non-Vacant\", 1, 0\n",
    ")\n",
    "\n",
    "sites_merge_df[\"abag_used_in_previous_he\"] = np.where(sites_merge_df[\"rhnacyc\"].notnull(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for export\n",
    "sites_merge_df.rename(\n",
    "    columns={\n",
    "        \"jurisdict_x\": \"jurisdiction\",\n",
    "        \"rhnacyc\": \"abag_rhna_cycle\",\n",
    "        \"rhnayrs\": \"abag_rhna_years\",\n",
    "        \"genplan\": \"abag_general_plan\",\n",
    "        \"zoning\": \"abag_zoning\",\n",
    "        \"allowden\": \"abag_allowable_density\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = [\n",
    "    \"jurisdiction\",\n",
    "    \"address\",\n",
    "    \"zip5\",\n",
    "    \"apn_fmt\",\n",
    "    \"con_sites\",\n",
    "    \"ex_gp_des\",\n",
    "    \"ex_zoning\",\n",
    "    \"min_dens\",\n",
    "    \"max_dens\",\n",
    "    \"acres\",\n",
    "    \"ex_use_vac\",\n",
    "    \"infra\",\n",
    "    \"public\",\n",
    "    \"site_stat\",\n",
    "    \"id_last2\",\n",
    "    \"li\",\n",
    "    \"mod\",\n",
    "    \"amod\",\n",
    "    \"capacity\",\n",
    "    \"opt1\",\n",
    "    \"opt2\",\n",
    "    \"abag_general_plan\",\n",
    "    \"abag_zoning\",\n",
    "    \"abag_allowable_density\",\n",
    "    \"abag_rhna_cycle\",\n",
    "    \"abag_rhna_years\",\n",
    "    \"sf_used_in_previous_he\",\n",
    "    \"abag_used_in_previous_he\",\n",
    "]\n",
    "final_sites_df = sites_merge_df.query(\"_merge == 'both' and sf_used_in_previous_he == 0\")[out_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1337, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sites_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export sites inventory\n",
    "final_sites_df.to_csv(\"Data/sf_recycled_sites.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
